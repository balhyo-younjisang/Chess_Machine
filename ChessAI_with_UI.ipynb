{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba93c5e6-f783-42a1-bed1-4b1c1e6d43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn #  PyTorch의 Neural Network 모듈을 포함하는 모듈\n",
    "import torch.optim as optim #  PyTorch에서 제공하는 최적화(optimizer) 알고리즘을 포함하는 모듈\n",
    "import chess\n",
    "import math\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, board, parent=None, action=None):\n",
    "        self.board = board  # 체스 보드 상태\n",
    "        self.parent = parent  # 부모 노드\n",
    "        self.children = []  # 자식 노드들\n",
    "        self.visit = 0  # 방문 횟수\n",
    "        self.wins = 0  # 승리 횟수\n",
    "        self.untried_moves = list(board.legal_moves)  # 아직 시도하지 않은 수들\n",
    "        self.game_over = board.is_game_over()\n",
    "        if self.game_over:\n",
    "            self.untried_moves = []\n",
    "        # action: 부모 노드에서 선택한 이동; 루트는 None\n",
    "        self.action = action  # action은 UCI 문자열 (예: \"e2e4\")\n",
    "\n",
    "    def uct_value(self):\n",
    "        if self.visit == 0:\n",
    "            return float('inf')\n",
    "        return self.wins / self.visit + math.sqrt(2 * math.log(self.parent.visit) / self.visit)\n",
    "\n",
    "    def best_child(self, policy_probabilities):\n",
    "        \"\"\"\n",
    "        자식 노드들 중에서 UCT 값과 정책 네트워크의 확률을 결합하여 가장 높은 값을 가진 자식을 선택\n",
    "        policy_probabilities: 현재 노드의 legal_moves에 대응하는 확률 배열 (길이 = len(legal_moves))\n",
    "        \"\"\"\n",
    "        max_value = float('-inf')\n",
    "        selected_child = None\n",
    "\n",
    "        legal_moves = list(self.board.legal_moves)\n",
    "        # 만약 정책 확률의 크기가 legal_moves와 다르면 에러 처리\n",
    "        if len(policy_probabilities) != len(legal_moves):\n",
    "            print(\"Error: Policy probabilities length does not match number of legal moves.\")\n",
    "            return None\n",
    "\n",
    "        for child in self.children:\n",
    "            # child.board.peek()는 자식 노드로 도달한 마지막 이동\n",
    "            move = child.board.peek()\n",
    "            if move not in legal_moves:\n",
    "                continue\n",
    "            move_index = legal_moves.index(move)\n",
    "            # 결합: UCT + 정책 확률(여기서는 단순 합산; 하이퍼파라미터 조정 가능)\n",
    "            value = child.uct_value() + policy_probabilities[move_index]\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                selected_child = child\n",
    "        return selected_child\n",
    "\n",
    "\n",
    "# 정책 네트워크 ( Policy Network )\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(PolicyNetwork, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(12, 32, kernel_size=3, stride=1, padding=1)  # Conv2D: 보드 상태를 특징 맵으로 변환\n",
    "      self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "      self.fc1 = nn.Linear(64 * 8 * 8, 256) # Fully Connected Layer ( 1차원 벡터로 변환 )\n",
    "      self.fc2 = nn.Linear(256, 4672) # 체스에서 가능한 수의 개수 ( 4672 개의 수 예측 )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.shape[0], -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # 확률 값 출력\n",
    "        return x\n",
    "\n",
    "# 가치 네트워크 (Value Network)\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(12, 32, kernel_size=3, stride=1, padding=1)  # Conv2D: 보드 상태를 특징 맵으로 변환\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # Fully connected layer (1차원 벡터로 변환)\n",
    "        self.fc2 = nn.Linear(256, 1)  # 승리 확률 예측\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))  # ReLU 활성화 함수\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.shape[0], -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))  # ReLU 활성화 함수\n",
    "        x = torch.sigmoid(self.fc2(x))  # 승리 확률 출력 (0~1 사이 값)\n",
    "        return x\n",
    "\n",
    "def move_to_index(move_uci):\n",
    "    return abs(hash(move_uci)) % 4672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32e9f185-c062-487c-88a0-e6a4872a3a4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PolicyNetwork:\n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"conv3.weight\", \"conv3.bias\", \"bn3.weight\", \"bn3.bias\", \"bn3.running_mean\", \"bn3.running_var\", \"bn3.num_batches_tracked\", \"conv4.weight\", \"conv4.bias\", \"bn4.weight\", \"bn4.bias\", \"bn4.running_mean\", \"bn4.running_var\", \"bn4.num_batches_tracked\", \"fc3.weight\", \"fc3.bias\". \n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 16384]) from checkpoint, the shape in current model is torch.Size([256, 4096]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([4672, 256]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([4672]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 174\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     app \u001b[38;5;241m=\u001b[39m QApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[1;32m--> 174\u001b[0m ex \u001b[38;5;241m=\u001b[39m ChessApp()\n\u001b[0;32m    175\u001b[0m ex\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    176\u001b[0m app\u001b[38;5;241m.\u001b[39mexec()\n",
      "Cell \u001b[1;32mIn[43], line 23\u001b[0m, in \u001b[0;36mChessApp.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net \u001b[38;5;241m=\u001b[39m ValueNetwork()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# weights_only 인자는 제거\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/policy_net_0328.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/value_net_0328.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PolicyNetwork:\n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"conv3.weight\", \"conv3.bias\", \"bn3.weight\", \"bn3.bias\", \"bn3.running_mean\", \"bn3.running_var\", \"bn3.num_batches_tracked\", \"conv4.weight\", \"conv4.bias\", \"bn4.weight\", \"bn4.bias\", \"bn4.running_mean\", \"bn4.running_var\", \"bn4.num_batches_tracked\", \"fc3.weight\", \"fc3.bias\". \n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 16384]) from checkpoint, the shape in current model is torch.Size([256, 4096]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([4672, 256]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([4672])."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import chess\n",
    "import chess.svg\n",
    "from PyQt5.QtWidgets import QApplication, QVBoxLayout, QWidget, QLabel\n",
    "from PyQt5.QtSvg import QSvgWidget\n",
    "from PyQt5.QtCore import Qt\n",
    "from PyQt5.QtGui import QMouseEvent\n",
    "import numpy as np\n",
    "\n",
    "class ChessApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.board = chess.Board()\n",
    "        self.selected_square = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.initUI()\n",
    "\n",
    "        # 모델 불러오기 및 평가모드 설정\n",
    "        self.policy_net = PolicyNetwork().to(self.device)\n",
    "        self.value_net = ValueNetwork().to(self.device)\n",
    "        # weights_only 인자는 제거\n",
    "        self.policy_net.load_state_dict(torch.load(\"./models/policy_net_0328.pth\", map_location=self.device, weights_only=True))\n",
    "        self.value_net.load_state_dict(torch.load(\"./models/value_net_0328.pth\", map_location=self.device, weights_only=True))\n",
    "        self.policy_net.eval()\n",
    "        self.value_net.eval()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('AI 체스')\n",
    "        self.setGeometry(100, 100, 500, 500)\n",
    "        \n",
    "        self.turn_label = QLabel(\"사용자의 턴\", self)\n",
    "        self.turn_label.setAlignment(Qt.AlignCenter)\n",
    "        \n",
    "        self.svg_widget = QSvgWidget()\n",
    "        self.svg_widget.setMouseTracking(True)\n",
    "        self.svg_widget.mousePressEvent = self.handle_click\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.svg_widget)\n",
    "        self.setLayout(layout)\n",
    "        self.update_board()\n",
    "\n",
    "    def update_board(self):\n",
    "        \"\"\"체스 보드를 업데이트하고 UI에 반영\"\"\"\n",
    "        last_move = self.board.peek() if self.board.move_stack else None\n",
    "        board_svg = chess.svg.board(self.board, lastmove=last_move)\n",
    "        self.svg_widget.load(bytearray(board_svg, encoding='utf-8'))\n",
    "\n",
    "    def handle_click(self, event: QMouseEvent):\n",
    "        if self.board.turn != chess.WHITE:\n",
    "            return  # 사용자의 턴이 아닐 때 클릭 무시\n",
    "        \"\"\"체스 보드를 클릭하면 사용자의 수를 처리\"\"\"\n",
    "        file = event.x() // (self.svg_widget.width() // 8)\n",
    "        rank = 7 - (event.y() // (self.svg_widget.height() // 8))\n",
    "        square = chess.square(file, rank)\n",
    "\n",
    "        if self.selected_square is None:\n",
    "            if self.board.piece_at(square) and self.board.color_at(square) == chess.WHITE:\n",
    "                self.selected_square = square\n",
    "        else:\n",
    "            move = chess.Move(self.selected_square, square)\n",
    "            if move in self.board.legal_moves:\n",
    "                self.board.push(move)\n",
    "                self.selected_square = None\n",
    "                self.update_board()\n",
    "                self.turn_label.setText(\"AI의 턴\")\n",
    "                QApplication.processEvents()\n",
    "                self.ai_move()  # AI의 턴 실행\n",
    "            else:\n",
    "                self.selected_square = None\n",
    "\n",
    "    def ai_move(self):\n",
    "        \"\"\"AI의 수를 계산하고 실행 (MCTS와 신경망 결합)\"\"\"\n",
    "        move = self.mcts_search(num_simulations=1500)\n",
    "        if move is None:\n",
    "            print(\"사용자 승리\")\n",
    "            self.closeEvent()\n",
    "        elif move:\n",
    "            self.board.push(move)\n",
    "            self.update_board()\n",
    "            self.turn_label.setText(\"사용자의 턴\")\n",
    "\n",
    "    # 헬퍼 함수: 체스 보드를 텐서로 변환\n",
    "    def board_to_tensor(self, board, device):\n",
    "        piece_map = {\n",
    "            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "        }\n",
    "        board_matrix = np.zeros((12, 8, 8), dtype=np.float32)\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                row, col = divmod(square, 8)\n",
    "                board_matrix[piece_map[piece.symbol()], row, col] = 1\n",
    "        tensor = torch.tensor(board_matrix, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        return tensor\n",
    "\n",
    "    # MCTS와 정책-가치 신경망을 결합한 수 선택 함수\n",
    "    def mcts_search(self, num_simulations=1500):\n",
    "        # 현재 보드를 사용하여 MCTS 탐색 시작 (self.board)\n",
    "        root = Node(self.board.copy())\n",
    "        c_puct = 2.0  # 탐험 상수\n",
    "\n",
    "        for _ in range(num_simulations):\n",
    "            node = root\n",
    "            simulation_board = self.board.copy()\n",
    "\n",
    "            # 선택 단계: leaf 노드까지 내려감\n",
    "            while node.untried_moves == [] and node.children:\n",
    "                tensor = self.board_to_tensor(simulation_board, self.device)\n",
    "                with torch.no_grad():\n",
    "                    logits = self.policy_net(tensor)\n",
    "                    probs = torch.softmax(logits, dim=1).cpu().numpy().flatten()\n",
    "                legal_moves = list(simulation_board.legal_moves)\n",
    "                legal_probs = np.array([probs[move_to_index(move.uci())] for move in legal_moves])\n",
    "                if legal_probs.sum() > 0:\n",
    "                    legal_probs = legal_probs / legal_probs.sum()\n",
    "                else:\n",
    "                    legal_probs = np.ones(len(legal_moves)) / len(legal_moves)\n",
    "                best_value = -float('inf')\n",
    "                best_child = None\n",
    "                for child in node.children:\n",
    "                    move = chess.Move.from_uci(child.action)\n",
    "                    if move not in legal_moves:\n",
    "                        continue\n",
    "                    move_index = legal_moves.index(move)\n",
    "                    Q = child.wins / child.visit if child.visit > 0 else 0\n",
    "                    U = c_puct * legal_probs[move_index] * math.sqrt(node.visit) / (1 + child.visit)\n",
    "                    value = Q + U\n",
    "                    if value > best_value:\n",
    "                        best_value = value\n",
    "                        best_child = child\n",
    "                if best_child is None:\n",
    "                    break\n",
    "                simulation_board.push(chess.Move.from_uci(best_child.action))\n",
    "                node = best_child\n",
    "\n",
    "            # 확장 단계\n",
    "            if node.untried_moves:\n",
    "                move = node.untried_moves.pop()\n",
    "                simulation_board.push(move)\n",
    "                new_node = Node(simulation_board.copy(), parent=node, action=move.uci())\n",
    "                node.children.append(new_node)\n",
    "                node = new_node\n",
    "\n",
    "            # 시뮬레이션 단계: 가치 네트워크 평가\n",
    "            tensor = self.board_to_tensor(simulation_board, self.device)\n",
    "            with torch.no_grad():\n",
    "                value = self.value_net(tensor).item()\n",
    "\n",
    "            # 백프로파게이션 단계\n",
    "            while node is not None:\n",
    "                node.visit += 1\n",
    "                node.wins += value\n",
    "                node = node.parent\n",
    "        \n",
    "        if root.children is None:\n",
    "            return None\n",
    "            \n",
    "        best_node = max(root.children, key=lambda n: n.visit)\n",
    "        return chess.Move.from_uci(best_node.action)\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        print(\"체스 애플리케이션 종료 중...\")\n",
    "        self.close()\n",
    "        event.accept()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if QApplication.instance() is None:\n",
    "        app = QApplication(sys.argv)\n",
    "    else:\n",
    "        app = QApplication.instance()\n",
    "    ex = ChessApp()\n",
    "    ex.show()\n",
    "    app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939b429-07cc-49ee-ab56-fbb6181c56c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
